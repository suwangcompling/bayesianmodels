{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "* Multinomial Bimodal Topic Model (Properties $\\sim$ Multinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Prepare Input\n",
    "\n",
    "* norms: list of all McRae norms (541)\n",
    "* props: list of all McRae properties (2526)\n",
    "* norm2prop: norm -> prop mapping\n",
    "* corpus triples: (word, dep, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norms,norm2prop,norm2propprob,props = cPickle.load(open(\"/Users/jacobsw/Desktop/UNIV/FALL_2016/LIN389C_RSCH_COMPLING/BAYESIAN/DATA/MCRAE/mcare_norm_data.p\",'rb'))\n",
    "dep_triples = cPickle.load(open(\"/Users/jacobsw/Desktop/UNIV/FALL_2016/LIN389C_RSCH_COMPLING/BAYESIAN/DATA/BROWN/brown_triples.p\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norms = list(set(norms)) # ignore polysemy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from __future__ import division\n",
    "from operator import add\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HELPERs\n",
    "\n",
    "def normalize(arr):\n",
    "    return arr / arr.sum()\n",
    "\n",
    "def partition(l, k):\n",
    "    k = max(1, k)\n",
    "    chunk_size = len(l)//k\n",
    "    return [l[i:i+chunk_size] for i in xrange(0, len(l), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EVALUATORS\n",
    "\n",
    "def topk_evaluate(norm2propdist, k): # test norms.\n",
    "    accuracies = []\n",
    "    for norm in norm2propdist.iterkeys():\n",
    "        true_props = norm2prop[norm]\n",
    "        pred_props = map(lambda idx:props[idx], np.argsort(norm2propdist[norm])[::-1][:k])\n",
    "        accuracy = 0.\n",
    "        for pred_prop in pred_props:\n",
    "            if pred_prop in true_props: \n",
    "                accuracy = 1. # gold-standard prop retrieved, count 'accuracy'.\n",
    "                break\n",
    "        accuracies.append(accuracy)\n",
    "    print \"Percentage Accurate (Test Norms) in Top %d Predictions: %.6f%%\" % (k, np.mean(accuracies)*100)\n",
    "\n",
    "def map_evaluate(norm2propdist):\n",
    "    avg_precs = []\n",
    "    for norm in norm2propdist.iterkeys():\n",
    "        true_propbin = np.array([1 if prop in norm2prop[norm] else 0 for prop in props])\n",
    "        pred_propdist = norm2propdist[norm]\n",
    "        avg_precs.append(average_precision_score(true_propbin, pred_propdist))\n",
    "    print \"MAP: %.6f%%\" % (np.mean(avg_precs)*100)\n",
    "    \n",
    "def map_ranker(norm2propdist):\n",
    "    norm2ap_tuples = []\n",
    "    for norm in norm2propdist.iterkeys():\n",
    "        true_propbin = np.array([1 if prop in norm2prop[norm] else 0 for prop in props])\n",
    "        pred_propdist = norm2propdist[norm]\n",
    "        norm2ap_tuples.append((norm,average_precision_score(true_propbin, pred_propdist)))\n",
    "    norm_by_ap = sorted(norm2ap_tuples, key=lambda x:x[1], reverse=True)\n",
    "    print \"Top 20 norms by AP:\"\n",
    "    print pd.DataFrame(norm_by_ap[:20], columns=['Concepts','AP'])\n",
    "    print \"Bottom 20 norms by AP:\"\n",
    "    print pd.DataFrame(norm_by_ap[-20:], columns=['Concepts','AP'])\n",
    "    print \"Standard Deviation of APs:\"\n",
    "    print np.std(map(lambda (n,ap):ap, norm2ap_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference Math\n",
    "\n",
    "* Given a new word $u$ is observed, in a corpus $\\mathcal{C}$, to have been the argument of a set of VR pairs $VR=\\{vr:pred(vr,u)\\in\\mathcal{C}\\}$. Then, the PDF of the distribution over properties $f\\in F$ conditioned on $VR$ is \n",
    "$$p(f\\mid VR)=\\sum_{z}p(f\\mid z)p(z\\mid VR)$$\n",
    "where $$p(z\\mid VR) = \\sum_{vr\\in VR}p(z\\mid vr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WPMBTM:\n",
    "    \n",
    "    def __init__(self, norms, props, norm2prop, norm2propprob, triples):\n",
    "        self.all_norms = norms # train-test split later.\n",
    "        self.props = props\n",
    "        self.n2i = {n:i for i,n in enumerate(self.all_norms)} # indexing pseudo-docs, each corresponds to 1 train norm.\n",
    "        self.f2i = {f:i for i,f in enumerate(self.props)}\n",
    "        self.norm2prop = norm2prop\n",
    "        self.norm2propprob = norm2propprob\n",
    "        self.triples = triples\n",
    "        self.preprocessing()\n",
    " \n",
    "    def preprocessing(self):\n",
    "        # construct norm2vr and norm2f mappings.\n",
    "        all_norms_set = set(self.all_norms) # for fast lookup.\n",
    "        self.norm2vr_f = defaultdict(lambda : defaultdict(list))\n",
    "        for norm,dep,head in self.triples:\n",
    "            if norm in all_norms_set and (dep=='nsubj' or dep=='dobj'):\n",
    "                vr = head+'-'+dep\n",
    "                f = np.random.choice(self.norm2prop[norm],p=self.norm2propprob[norm])\n",
    "                self.norm2vr_f[norm]['vr'].append(vr)\n",
    "                self.norm2vr_f[norm]['f'].append(f)\n",
    "        self.all_norms = self.norm2vr_f.keys() # narrow it down to norms appearing in the current corpus.\n",
    "        \n",
    "    def learn(self, train_norms, topics):\n",
    "        # make pseudo-documents.\n",
    "        vrs = set() \n",
    "        norm2vr_f = deepcopy(self.norm2vr_f) # avoid subtle changes to the original mapping dict.\n",
    "        word_docs, prop_docs = [], [] # word_docs: for v-r pairs.\n",
    "        for norm in train_norms:\n",
    "            word_docs.append(norm2vr_f[norm]['vr'])\n",
    "            prop_docs.append(norm2vr_f[norm]['f'])\n",
    "            vrs = vrs.union(set(norm2vr_f[norm]['vr']))\n",
    "        vrs = list(vrs)\n",
    "        w2i = {vr:i for i,vr in enumerate(vrs)} \n",
    "        for word_doc,prop_doc in zip(word_docs,prop_docs):\n",
    "            for i,(word,prop) in enumerate(zip(word_doc,prop_doc)):\n",
    "                sampled_topic = np.random.choice(topics)\n",
    "                word_doc[i] = (word,sampled_topic)\n",
    "                prop_doc[i] = (prop,sampled_topic)\n",
    "        # topic modeling\n",
    "        print \"... Running Topic Model\"\n",
    "        W, F, D, T = len(vrs), len(self.props), len(word_docs), len(topics)\n",
    "        alpha, beta, gamma = 50/2, .001, .001\n",
    "        alpha_arr = np.array([alpha for _ in range(T)]); Talpha_arr = np.array([alpha*T for _ in range(T)])\n",
    "        beta_arr = np.array([beta for _ in range(T)]); Wbeta_arr = np.array([beta*W for _ in range(T)])\n",
    "        gamma_arr = np.array([gamma for _ in range(T)]); Fgamma_arr = np.array([gamma*F for _ in range(T)])\n",
    "        C_WT, C_FT, C_DT = np.zeros((W,T)), np.zeros((F,T)), np.zeros((D,T))\n",
    "        wt_counts = reduce(add,[Counter(word_doc) for word_doc in word_docs])\n",
    "        ft_counts = reduce(add,[Counter(prop_doc) for prop_doc in prop_docs])\n",
    "        for (w,t_w),wt_count in wt_counts.iteritems(): C_WT[w2i[w]][t_w] = wt_count \n",
    "        for (f,t_f),ft_count in ft_counts.iteritems(): C_FT[self.f2i[f]][t_f] = ft_count\n",
    "        for i,doc in enumerate(word_docs): # word,property pairs have the same topic assignments.\n",
    "            dt_counts = Counter([t for w,t in doc])\n",
    "            for j in range(T):\n",
    "                C_DT[i][j] = dt_counts[j]\n",
    "        if not C_WT.sum()==C_FT.sum()==C_DT.sum():\n",
    "            raise Exception, \"Error in counts in pseudo-document.\"\n",
    "        def sample_topic(w_i,f_i,d): # defined locally to avoid passing around big matrices.\n",
    "            P_num_arr = (C_WT[w_i,:]+beta_arr) * (C_FT[f_i,:]+gamma_arr) * (C_DT[d,:]+alpha_arr)\n",
    "            P_denom_arr = (np.apply_along_axis(sum,0,C_WT)+Wbeta_arr) * \\\n",
    "                          (np.apply_along_axis(sum,0,C_FT)+Fgamma_arr) * \\\n",
    "                          (T * (C_DT[d,:].sum()+T*alpha))\n",
    "            P = normalize(P_num_arr / P_denom_arr)\n",
    "            return np.random.choice(np.array(topics),p=normalize(P)) \n",
    "        def gibbs(n_iters=30, verbose_freq=5): # 30: experimentally where the convergence is achieved.\n",
    "            for e in range(n_iters):\n",
    "                if e!=0 and e%verbose_freq==0: print \"@ %dth iteration\" % e\n",
    "                for d,(word_doc,prop_doc) in enumerate(zip(word_docs,prop_docs)):\n",
    "                    for (w,t),(f,_) in zip(word_doc,prop_doc): # a (w,f) pair have the same topic.\n",
    "                        if C_WT[w2i[w]][t]==0 or C_FT[self.f2i[f]][t]==0 or C_DT[d][t]==0: continue\n",
    "                        C_WT[w2i[w]][t] -= 1\n",
    "                        C_FT[self.f2i[f]][t] -= 1\n",
    "                        C_DT[d][t] -= 1\n",
    "                        new_t = sample_topic(w2i[w],self.f2i[f],d)\n",
    "                        C_WT[w2i[w]][new_t] += 1\n",
    "                        C_FT[self.f2i[f]][new_t] += 1\n",
    "                        C_DT[d][new_t] += 1\n",
    "        gibbs()\n",
    "        return C_WT, C_FT, w2i\n",
    "        \n",
    "    def infer(self, cv=5, topics=range(100)): # cv >= 2\n",
    "        # norm set chunking\n",
    "        random.shuffle(self.all_norms)\n",
    "        norm_chunks = partition(self.all_norms, cv)\n",
    "        self.results = []\n",
    "        for i in range(cv):\n",
    "            print \"... Running CV round %d\" % (i+1)\n",
    "            train_norms = list(chain.from_iterable([norm_chunk for j,norm_chunk in enumerate(norm_chunks)\n",
    "                                                    if j!=i])) # flatten.\n",
    "            test_norms = norm_chunks[i]\n",
    "            C_WT, C_FT, w2i = self.learn(train_norms, topics)\n",
    "            def p_z_given_vr(z, vr):\n",
    "                return C_WT[w2i[vr]][z] / C_WT[w2i[vr],:].sum()\n",
    "            def p_f_given_z(f, z):\n",
    "                return C_FT[self.f2i[f]][z] / C_FT[:,z].sum()\n",
    "            norm2propdist = defaultdict(list)\n",
    "            for norm in test_norms:\n",
    "                vrs = list(set(self.norm2vr_f[norm]['vr']))\n",
    "                p_z_arr = [sum(p_z_given_vr(z,vr) if vr in w2i else 0. for vr in vrs) for z in topics]\n",
    "                p_f_arr = [np.dot([p_f_given_z(f,z) for z in topics],p_z_arr) for f in self.props]\n",
    "                norm2propdist[norm] = p_f_arr\n",
    "            self.results.append(norm2propdist)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        for i,norm2propdist in enumerate(self.results):\n",
    "            print \"CV round %d results:\" % (i+1)\n",
    "            topk_evaluate(norm2propdist, k=1)\n",
    "            topk_evaluate(norm2propdist, k=5)\n",
    "            topk_evaluate(norm2propdist, k=10)\n",
    "            topk_evaluate(norm2propdist, k=20)\n",
    "            map_evaluate(norm2propdist)\n",
    "            map_ranker(norm2propdist)\n",
    "            print  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Running CV round 1\n",
      "... Running Topic Model\n",
      "@ 5th iteration\n",
      "@ 10th iteration\n",
      "@ 15th iteration\n",
      "@ 20th iteration\n",
      "@ 25th iteration\n",
      "... Running CV round 2\n",
      "... Running Topic Model\n",
      "@ 5th iteration\n",
      "@ 10th iteration\n",
      "@ 15th iteration\n",
      "@ 20th iteration\n",
      "@ 25th iteration\n",
      "... Running CV round 3\n",
      "... Running Topic Model\n",
      "@ 5th iteration\n",
      "@ 10th iteration\n",
      "@ 15th iteration\n",
      "@ 20th iteration\n",
      "@ 25th iteration\n",
      "... Running CV round 4\n",
      "... Running Topic Model\n",
      "@ 5th iteration\n",
      "@ 10th iteration\n",
      "@ 15th iteration\n",
      "@ 20th iteration\n",
      "@ 25th iteration\n",
      "... Running CV round 5\n",
      "... Running Topic Model\n",
      "@ 5th iteration\n",
      "@ 10th iteration\n",
      "@ 15th iteration\n",
      "@ 20th iteration\n",
      "@ 25th iteration\n",
      "CPU times: user 28min 59s, sys: 10.9 s, total: 29min 10s\n",
      "Wall time: 29min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wpmbtm = WPMBTM(norms, props, norm2prop, norm2propprob, dep_triples)\n",
    "wpmbtm.infer(cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV round 1 results:\n",
      "Percentage Accurate (Test Norms) in Top 1 Predictions: 10.769231%\n",
      "Percentage Accurate (Test Norms) in Top 5 Predictions: 35.384615%\n",
      "Percentage Accurate (Test Norms) in Top 10 Predictions: 44.615385%\n",
      "Percentage Accurate (Test Norms) in Top 20 Predictions: 56.923077%\n",
      "MAP: 13.776234%\n",
      "Top 20 norms by AP:\n",
      "       Concepts        AP\n",
      "0           rat  0.504355\n",
      "1         eagle  0.503365\n",
      "2       peacock  0.503167\n",
      "3          wasp  0.503167\n",
      "4      parakeet  0.503167\n",
      "5     cockroach  0.502771\n",
      "6      goldfish  0.502771\n",
      "7          crow  0.502573\n",
      "8        shrimp  0.502573\n",
      "9         clamp  0.501979\n",
      "10       rattle  0.501781\n",
      "11      hatchet  0.501584\n",
      "12  nightingale  0.501188\n",
      "13        spade  0.242392\n",
      "14        baton  0.176938\n",
      "15        bench  0.171492\n",
      "16         duck  0.105279\n",
      "17        chair  0.103072\n",
      "18      thimble  0.101781\n",
      "19        spear  0.086105\n",
      "Bottom 20 norms by AP:\n",
      "       Concepts        AP\n",
      "0          gown  0.018096\n",
      "1         buggy  0.017945\n",
      "2      envelope  0.017757\n",
      "3          sock  0.016872\n",
      "4      squirrel  0.016378\n",
      "5          toad  0.015915\n",
      "6          hawk  0.014740\n",
      "7           pie  0.012319\n",
      "8           mat  0.012155\n",
      "9         sword  0.011862\n",
      "10        chain  0.011733\n",
      "11       walrus  0.011123\n",
      "12       pigeon  0.010699\n",
      "13      slipper  0.010396\n",
      "14         tape  0.007087\n",
      "15       pepper  0.004913\n",
      "16     basement  0.003167\n",
      "17  certificate  0.002375\n",
      "18      pumpkin  0.002375\n",
      "19       cellar  0.001979\n",
      "Standard Deviation of APs:\n",
      "0.187459171858\n",
      "\n",
      "CV round 2 results:\n",
      "Percentage Accurate (Test Norms) in Top 1 Predictions: 16.923077%\n",
      "Percentage Accurate (Test Norms) in Top 5 Predictions: 41.538462%\n",
      "Percentage Accurate (Test Norms) in Top 10 Predictions: 52.307692%\n",
      "Percentage Accurate (Test Norms) in Top 20 Predictions: 67.692308%\n",
      "MAP: 4.828781%\n",
      "Top 20 norms by AP:\n",
      "    Concepts        AP\n",
      "0        peg  0.399108\n",
      "1       boat  0.237897\n",
      "2       door  0.163882\n",
      "3     rocket  0.161067\n",
      "4      house  0.153498\n",
      "5     donkey  0.133568\n",
      "6    trouser  0.126701\n",
      "7     mitten  0.126380\n",
      "8   football  0.122122\n",
      "9       ring  0.099857\n",
      "10       bin  0.094265\n",
      "11    celery  0.086722\n",
      "12     scarf  0.077921\n",
      "13   sweater  0.059446\n",
      "14       cup  0.056700\n",
      "15  cupboard  0.052105\n",
      "16      tray  0.044002\n",
      "17   curtain  0.043777\n",
      "18      bowl  0.043547\n",
      "19       pin  0.041741\n",
      "Bottom 20 norms by AP:\n",
      "   Concepts        AP\n",
      "0      sack  0.014982\n",
      "1       bed  0.014673\n",
      "2   trailer  0.014494\n",
      "3    potato  0.014154\n",
      "4       dog  0.014147\n",
      "5    pillow  0.012579\n",
      "6      fork  0.011721\n",
      "7      jeep  0.011541\n",
      "8     peach  0.011316\n",
      "9     brush  0.011155\n",
      "10    clock  0.009425\n",
      "11   candle  0.007432\n",
      "12  lantern  0.007411\n",
      "13     tent  0.004857\n",
      "14  rooster  0.003563\n",
      "15   coyote  0.003365\n",
      "16     kite  0.002771\n",
      "17     plug  0.002573\n",
      "18     dove  0.001979\n",
      "19  bouquet  0.001584\n",
      "Standard Deviation of APs:\n",
      "0.0649572564826\n",
      "\n",
      "CV round 3 results:\n",
      "Percentage Accurate (Test Norms) in Top 1 Predictions: 12.307692%\n",
      "Percentage Accurate (Test Norms) in Top 5 Predictions: 40.000000%\n",
      "Percentage Accurate (Test Norms) in Top 10 Predictions: 55.384615%\n",
      "Percentage Accurate (Test Norms) in Top 20 Predictions: 72.307692%\n",
      "MAP: 9.122932%\n",
      "Top 20 norms by AP:\n",
      "       Concepts        AP\n",
      "0        turkey  0.503563\n",
      "1     butterfly  0.502969\n",
      "2       buffalo  0.502969\n",
      "3   caterpillar  0.502771\n",
      "4          bull  0.502375\n",
      "5    helicopter  0.501979\n",
      "6          clam  0.501584\n",
      "7         stick  0.222962\n",
      "8          cart  0.155873\n",
      "9          tank  0.119128\n",
      "10          box  0.107027\n",
      "11          tie  0.101580\n",
      "12        knife  0.097473\n",
      "13         drum  0.087458\n",
      "14        train  0.081076\n",
      "15         pony  0.078226\n",
      "16       saucer  0.076845\n",
      "17         mink  0.070790\n",
      "18        board  0.067913\n",
      "19          jet  0.064246\n",
      "Bottom 20 norms by AP:\n",
      "       Concepts        AP\n",
      "0    typewriter  0.016484\n",
      "1        pencil  0.015457\n",
      "2          comb  0.015340\n",
      "3     apartment  0.014437\n",
      "4         grape  0.013596\n",
      "5        radish  0.011834\n",
      "6        tripod  0.011066\n",
      "7          pear  0.010489\n",
      "8         lemon  0.008308\n",
      "9   thermometer  0.008118\n",
      "10       tomato  0.007907\n",
      "11       saddle  0.007356\n",
      "12         vine  0.007275\n",
      "13         doll  0.006471\n",
      "14         lamp  0.006439\n",
      "15        mouse  0.005938\n",
      "16       toilet  0.004818\n",
      "17      bedroom  0.004526\n",
      "18       sandal  0.003365\n",
      "19      whistle  0.002771\n",
      "Standard Deviation of APs:\n",
      "0.148101002013\n",
      "\n",
      "CV round 4 results:\n",
      "Percentage Accurate (Test Norms) in Top 1 Predictions: 12.307692%\n",
      "Percentage Accurate (Test Norms) in Top 5 Predictions: 32.307692%\n",
      "Percentage Accurate (Test Norms) in Top 10 Predictions: 46.153846%\n",
      "Percentage Accurate (Test Norms) in Top 20 Predictions: 55.384615%\n",
      "MAP: 8.767579%\n",
      "Top 20 norms by AP:\n",
      "     Concepts        AP\n",
      "0       canoe  0.503563\n",
      "1   pineapple  0.503365\n",
      "2        swan  0.503167\n",
      "3      subway  0.502771\n",
      "4        jean  0.502771\n",
      "5         owl  0.502573\n",
      "6       wagon  0.311193\n",
      "7      garage  0.244304\n",
      "8      bridge  0.234778\n",
      "9    building  0.204662\n",
      "10   bracelet  0.126856\n",
      "11         ox  0.122452\n",
      "12  slingshot  0.102914\n",
      "13      ruler  0.098272\n",
      "14       gate  0.092805\n",
      "15   umbrella  0.081110\n",
      "16        bat  0.076115\n",
      "17      table  0.069210\n",
      "18       ball  0.048667\n",
      "19     jacket  0.046747\n",
      "Bottom 20 norms by AP:\n",
      "       Concepts        AP\n",
      "0         level  0.013918\n",
      "1          bean  0.013519\n",
      "2      magazine  0.012955\n",
      "3        kettle  0.012411\n",
      "4          rope  0.011458\n",
      "5          moth  0.010797\n",
      "6         bread  0.010385\n",
      "7        garlic  0.009678\n",
      "8           tap  0.009635\n",
      "9         brick  0.009489\n",
      "10        radio  0.005536\n",
      "11       muzzle  0.005398\n",
      "12         lime  0.005310\n",
      "13         cake  0.003365\n",
      "14         frog  0.003167\n",
      "15       orange  0.003167\n",
      "16      bathtub  0.003167\n",
      "17  grasshopper  0.002573\n",
      "18   microscope  0.002573\n",
      "19      shotgun  0.001979\n",
      "Standard Deviation of APs:\n",
      "0.145479202594\n",
      "\n",
      "CV round 5 results:\n",
      "Percentage Accurate (Test Norms) in Top 1 Predictions: 10.769231%\n",
      "Percentage Accurate (Test Norms) in Top 5 Predictions: 32.307692%\n",
      "Percentage Accurate (Test Norms) in Top 10 Predictions: 43.076923%\n",
      "Percentage Accurate (Test Norms) in Top 20 Predictions: 58.461538%\n",
      "MAP: 6.600046%\n",
      "Top 20 norms by AP:\n",
      "     Concepts        AP\n",
      "0        pant  0.504157\n",
      "1        flea  0.503365\n",
      "2     sardine  0.502177\n",
      "3       cloak  0.501584\n",
      "4         bus  0.217785\n",
      "5       piano  0.119829\n",
      "6         cap  0.114084\n",
      "7   submarine  0.099471\n",
      "8      bullet  0.090729\n",
      "9     balloon  0.087609\n",
      "10    cabbage  0.083498\n",
      "11      pearl  0.073333\n",
      "12       goat  0.070627\n",
      "13      truck  0.068433\n",
      "14      horse  0.063539\n",
      "15        mug  0.057910\n",
      "16  ambulance  0.055434\n",
      "17       pipe  0.053378\n",
      "18     pistol  0.050742\n",
      "19    grenade  0.048824\n",
      "Bottom 20 norms by AP:\n",
      "     Concepts        AP\n",
      "0        lamb  0.015510\n",
      "1        sink  0.014881\n",
      "2       screw  0.012584\n",
      "3     cushion  0.012412\n",
      "4        corn  0.011433\n",
      "5        book  0.010381\n",
      "6        whip  0.010047\n",
      "7   cigarette  0.009282\n",
      "8   telephone  0.008779\n",
      "9     avocado  0.008665\n",
      "10        fan  0.008103\n",
      "11       bomb  0.007242\n",
      "12        toy  0.006239\n",
      "13     carrot  0.003563\n",
      "14        van  0.002969\n",
      "15     stereo  0.002969\n",
      "16      drill  0.002177\n",
      "17        cod  0.001781\n",
      "18       menu  0.001584\n",
      "19     buckle  0.001584\n",
      "Standard Deviation of APs:\n",
      "0.117455858121\n",
      "\n",
      "CPU times: user 1.58 s, sys: 19.7 ms, total: 1.6 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wpmbtm.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### CV = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wpmbtm = WPMBTM(norms, props, norm2prop, norm2propprob, dep_triples)\n",
    "# wpmbtm.infer(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wpmbtm.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
