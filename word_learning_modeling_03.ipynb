{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model III\n",
    "\n",
    "* **Norms**: McRae et al. (2005)\n",
    "\n",
    "* **Model**: Simple Model Inspired by Erk (2016) Examples\n",
    "    * Idea: The properties of an unknown word are informed by its position in its argument structure (core or core + peripheral).\n",
    "    * Scope (current model): Only core-argument positions.\n",
    "    * Probability for a New Word $w$ to have $prop$: Let $v$ be the predicate, then\n",
    "        * General: $p_{subj}(prop\\mid v) \\propto \\sum_{subj\\in v_{subj}}p(prop\\mid subj)p(subj\\mid v)$, similar for $obj$.\n",
    "        * Specific: $p_{subj}(prop\\mid v,obj) \\propto \\sum_{subj\\in v_{subj}}p(prop\\mid subj)p(subj\\mid v,obj)$, similar for $obj$.\n",
    "        * NB: $v_{subj}$ and $v_{obj}$ are cohorts of an unknown word $w$. For instance, if $w$ is 'alligator', which appears in the sentence 'a guy is feeding an alligator', then the cohort $v_obj$ would be all the objects of $v$ as appeared in a selected corpus.\n",
    "\n",
    "* **Algorithm**:\n",
    "    * Let $W$ be the set of norm nouns ($W_{subj},W_{obj}$ are subj/obj-only sets), $V$ be the set of verbs which have at least one $w\\in W$ evidenced in its core argument position, $P$ be the set of properties.\n",
    "    * Build cooccurrence matrices $S_{|V_{subj}|\\times|W_{subj}|}$ and $O_{|V_{obj}|\\times|W_{obj}|}$ from corpus.\n",
    "    * Build cooccurrence matrices $S'_{|W_{subj}|\\times|P|}$ and $O'_{|W_{obj}|\\times|P|}$ from McRae norms.\n",
    "    * Obtain distributions $p_{subj}(prop\\mid v)$ or $p_{subj}(prop\\mid v, o)$ (similar for $obj$) using matrices $S,S',O,O'$.\n",
    "    * On encountering a new/unknown word $w_{subj}$ or $w_{obj}$ in sentence $s$ with predicate $v$,\n",
    "        * Find $w$'s paradigmatic cohort, i.e. $v_{subj}$ or $v_{obj}$,\n",
    "        * Compute $p_{subj}(prop\\mid v)$ or $p_{subj}(prop\\mid v, o)$ for $prop\\in P$ using the cohort,\n",
    "        * (Partial) Bayesian Update:\n",
    "            * Case 1: If $w$ is completed **unseen** before, update $w$'s probability distribution over properties with this $p_{subj/obj}$.\n",
    "            * Case 2: Otherwise, perform pointwise multiplication of $w$'s probability distribution over properties and the newly computed distribution, then normalize the result (i.e. expected distribution), before updating $w$'s distribution with it.\n",
    "            * Notes:\n",
    "                * The update is *partial*, because we only investigate the learning of a single new word in a few examples, but leave the trained \"information/knowledge state\" unupdated.\n",
    "                * Note that *unseen* is not *unknown*. For instance, despite the fact I've seen 'elm' appearing multiple times, I cannot point to an object and call it 'elm'. 'elm' is therefore an unknown, but not unseen, word to me.\n",
    "    * Evaluation: Return top $k$ $prop$s as a hypothesis for $w$'s property set.\n",
    "\n",
    "* **Comments**:\n",
    "    * $p_{subj}(prop\\mid v, o)$ could be an immensely sparse distribution.\n",
    "    * If we had higher coverage on noun properties, taking the insersection of properties for $v_{subj/obj}$ is perhaps a better reflection of our intuition -- this intersection is the common properties for words in $subj$ or $obj$ position of $v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/CODER/IMPLEMENTATION_CAMP/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/DATA/McRae-BRM-InPress/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"CONCS_FEATS_concstats_brm.xls\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Concept', u'Feature', u'WB_Label', u'WB_Maj', u'WB_Min', u'BR_Label',\n",
      "       u'Prod_Freq', u'Rank_PF', u'Sum_PF_No_Tax', u'CPF', u'Disting',\n",
      "       u'Distinct', u'CV_No_Tax', u'Intercorr_Str_Tax',\n",
      "       u'Intercorr_Str_No_Tax', u'Feat_Length_Including_Spaces', u'Phon_1st',\n",
      "       u'KF', u'ln(KF)', u'BNC', u'ln(BNC)', u'Familiarity', u'Length_Letters',\n",
      "       u'Length_Phonemes', u'Length_Syllables', u'Bigram', u'Trigram',\n",
      "       u'ColtheartN', u'Num_Feats_Tax', u'Num_Feats_No_Tax',\n",
      "       u'Num_Disting_Feats_No_Tax', u'Disting_Feats_%_No_Tax',\n",
      "       u'Mean_Distinct_No_Tax', u'Mean_CV_No_Tax', u'Density_No_Tax',\n",
      "       u'Num_Corred_Pairs_No_Tax', u'%_Corred_Pairs_No_Tax', u'Num_Func',\n",
      "       u'Num_Vis_Mot', u'Num_VisF&S', u'Num_Vis_Col', u'Num_Sound',\n",
      "       u'Num_Taste', u'Num_Smell', u'Num_Tact', u'Num_Ency', u'Num_Tax'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept</th>\n",
       "      <th>Feature</th>\n",
       "      <th>WB_Label</th>\n",
       "      <th>WB_Maj</th>\n",
       "      <th>WB_Min</th>\n",
       "      <th>BR_Label</th>\n",
       "      <th>Prod_Freq</th>\n",
       "      <th>Rank_PF</th>\n",
       "      <th>Sum_PF_No_Tax</th>\n",
       "      <th>CPF</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_Func</th>\n",
       "      <th>Num_Vis_Mot</th>\n",
       "      <th>Num_VisF&amp;S</th>\n",
       "      <th>Num_Vis_Col</th>\n",
       "      <th>Num_Sound</th>\n",
       "      <th>Num_Taste</th>\n",
       "      <th>Num_Smell</th>\n",
       "      <th>Num_Tact</th>\n",
       "      <th>Num_Ency</th>\n",
       "      <th>Num_Tax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accordion</td>\n",
       "      <td>a_musical_instrument</td>\n",
       "      <td>superordinate</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>taxonomic</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accordion</td>\n",
       "      <td>associated_with_polkas</td>\n",
       "      <td>associated_entity</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "      <td>encyclopaedic</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accordion</td>\n",
       "      <td>has_buttons</td>\n",
       "      <td>external_component</td>\n",
       "      <td>e</td>\n",
       "      <td>ce</td>\n",
       "      <td>visual-form_and_surface</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>163.0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accordion</td>\n",
       "      <td>has_keys</td>\n",
       "      <td>external_component</td>\n",
       "      <td>e</td>\n",
       "      <td>ce</td>\n",
       "      <td>visual-form_and_surface</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>108.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accordion</td>\n",
       "      <td>inbeh_-_produces_music</td>\n",
       "      <td>entity_behavior</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>sound</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>178.0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accordion</td>\n",
       "      <td>is_loud</td>\n",
       "      <td>external_surface_property</td>\n",
       "      <td>e</td>\n",
       "      <td>se</td>\n",
       "      <td>sound</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>317.0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accordion</td>\n",
       "      <td>requires_air</td>\n",
       "      <td>contingency</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>encyclopaedic</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accordion</td>\n",
       "      <td>used_by_moving_bellows</td>\n",
       "      <td>action</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>function</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>accordion</td>\n",
       "      <td>worn_on_chest</td>\n",
       "      <td>function</td>\n",
       "      <td>s</td>\n",
       "      <td>f</td>\n",
       "      <td>function</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airplane</td>\n",
       "      <td>beh_-_flies</td>\n",
       "      <td>entity_behavior</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>visual-motion</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>712.0</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Concept                 Feature                   WB_Label WB_Maj WB_Min  \\\n",
       "0  accordion    a_musical_instrument              superordinate      c      h   \n",
       "1  accordion  associated_with_polkas          associated_entity      s      e   \n",
       "2  accordion             has_buttons         external_component      e     ce   \n",
       "3  accordion                has_keys         external_component      e     ce   \n",
       "4  accordion  inbeh_-_produces_music            entity_behavior      e      b   \n",
       "5  accordion                 is_loud  external_surface_property      e     se   \n",
       "6  accordion            requires_air                contingency      i      c   \n",
       "7  accordion  used_by_moving_bellows                     action      s      a   \n",
       "8  accordion           worn_on_chest                   function      s      f   \n",
       "9   airplane             beh_-_flies            entity_behavior      e      b   \n",
       "\n",
       "                  BR_Label  Prod_Freq  Rank_PF  Sum_PF_No_Tax  CPF   ...     \\\n",
       "0                taxonomic         28        1            NaN   18   ...      \n",
       "1            encyclopaedic          9        4            9.0    1   ...      \n",
       "2  visual-form_and_surface          8        5          163.0   13   ...      \n",
       "3  visual-form_and_surface         17        2          108.0    7   ...      \n",
       "4                    sound          6        7          178.0   13   ...      \n",
       "5                    sound          6        7          317.0   34   ...      \n",
       "6            encyclopaedic         11        3           49.0    4   ...      \n",
       "7                 function          8        5            8.0    1   ...      \n",
       "8                 function          6        7            6.0    1   ...      \n",
       "9            visual-motion         25        1          712.0   46   ...      \n",
       "\n",
       "  Num_Func  Num_Vis_Mot  Num_VisF&S  Num_Vis_Col  Num_Sound  Num_Taste  \\\n",
       "0        2            0           2            0          2          0   \n",
       "1        2            0           2            0          2          0   \n",
       "2        2            0           2            0          2          0   \n",
       "3        2            0           2            0          2          0   \n",
       "4        2            0           2            0          2          0   \n",
       "5        2            0           2            0          2          0   \n",
       "6        2            0           2            0          2          0   \n",
       "7        2            0           2            0          2          0   \n",
       "8        2            0           2            0          2          0   \n",
       "9        3            3           5            0          0          0   \n",
       "\n",
       "  Num_Smell  Num_Tact  Num_Ency  Num_Tax  \n",
       "0         0         0         2        1  \n",
       "1         0         0         2        1  \n",
       "2         0         0         2        1  \n",
       "3         0         0         2        1  \n",
       "4         0         0         2        1  \n",
       "5         0         0         2        1  \n",
       "6         0         0         2        1  \n",
       "7         0         0         2        1  \n",
       "8         0         0         2        1  \n",
       "9         0         0         2        0  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_sents = [unicode(' '.join(sent)) for sent in brown.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 806 ms, total: 1min 35s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsed_sents = [parser(sent) for sent in brown_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_token2lemma_dict(parsed_sents):\n",
    "    \n",
    "    lemmas = set()\n",
    "    token2lemma = {}\n",
    "    for parsed_sent in parsed_sents:\n",
    "        for token in parsed_sent:\n",
    "            token2lemma[token.orth_] = token.lemma_\n",
    "            lemmas.add(token.lemma_)\n",
    "    \n",
    "    return lemmas, token2lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 19.1 ms, total: 1.22 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brown_lemmas, brown_t2l = make_token2lemma_dict(parsed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book\n"
     ]
    }
   ],
   "source": [
    "print brown_t2l['books']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Synchronize Norms & Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norms = {df.ix[i]['Concept'] for i in range(df.shape[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_normalize(norm):\n",
    "    \n",
    "    norm = norm.split('_')[0] if '_' in norm else norm\n",
    "    if norm in brown_t2l: return brown_t2l[norm]\n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "print norm_normalize('cat_(kitchen)')\n",
    "print norm_normalize('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Out-Of-Vocab Norms For Brown\n",
    "t = [] \n",
    "for norm in norms:\n",
    "    norm = norm.split('_')[0] if '_' in norm else norm\n",
    "    if norm in brown_lemmas or norm in brown_t2l: continue\n",
    "    t.append(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earmuffs', 'bike', 'screwdriver', 'unicycle', 'camisole', 'crossbow', 'hamster', 'bra', 'sledgehammer', 'skateboard', 'leotards', 'rhubarb', 'platypus', 'pelican', 'minnow', 'canary', 'spatula', 'motorcycle', 'iguana', 'chickadee', 'giraffe', 'tricycle', 'bazooka', 'tomahawk', 'ostrich', 'cucumber', 'lettuce', 'whale', 'stork', 'bluejay', 'colander', 'chipmunk', 'escalator', 'partridge', 'parka', 'zucchini', 'dunebuggy', 'machete', 'crowbar', 'housefly', 'blender', 'nectarine', 'scooter', 'cougar', 'penguin', 'emu', 'honeydew', 'wheelbarrow', 'harmonica', 'eggplant', 'groundhog', 'harpoon', 'yam', 'squid', 'toaster', 'moose', 'tuna', 'surfboard', 'nylons', 'raven', 'budgie', 'fridge', 'gopher', 'flamingo', 'sleigh', 'trombone', 'strainer', 'dagger', 'chimp', 'buzzard', 'guppy', 'grater', 'nightgown', 'cello', 'hornet', 'finch', 'tangerine', 'gorilla', 'caribou']\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print t\n",
    "print len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SPECIAL BLOCK: FOR LEAVE-ONE-OUT **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out_word = 'alligator'\n",
    "# norms = filter(lambda norm: norm!=out_word, map(lambda norm:norm_normalize(norm), norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norms = map(lambda norm:norm_normalize(norm), norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norms_set = set(norms) # for faster lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Build $S,S'$ & $O,O'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. $W_{subj}, W_{obj}$ & $V_{subj}, V_{obj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_dep_triples(parsed_sents):\n",
    "    \n",
    "    triples = []\n",
    "    for parsed_sent in parsed_sents:\n",
    "        for token in parsed_sent:\n",
    "            lemma_triple = (token.lemma_, token.dep_, token.head.lemma_)\n",
    "            triples.append(lemma_triple)\n",
    "    \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 136 ms, total: 1.28 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dep_triples = extract_dep_triples(parsed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_w_set(triples, mode):\n",
    "    \n",
    "    w_set = set()\n",
    "    for triple in triples:\n",
    "        if triple[1].endswith(mode) and triple[0] in norms_set:\n",
    "            w_set.add(triple[0])\n",
    "    \n",
    "    return w_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 765 ms, sys: 15.6 ms, total: 781 ms\n",
      "Wall time: 772 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W_subj = get_w_set(dep_triples, mode='subj')\n",
    "W_obj = get_w_set(dep_triples, mode='obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 394\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "print len(W_subj), len(W_obj)\n",
    "print len(W_subj.intersection(W_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_v_set(triples, mode):\n",
    "    \n",
    "    v_set = set()\n",
    "    for triple in triples:\n",
    "        if triple[1].endswith(mode):\n",
    "            v_set.add(triple[2])\n",
    "    \n",
    "    return v_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 780 ms, sys: 8.01 ms, total: 788 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "V_subj = get_v_set(dep_triples, 'subj')\n",
    "V_obj = get_v_set(dep_triples, 'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754 3319\n",
      "2554\n"
     ]
    }
   ],
   "source": [
    "print len(V_subj), len(V_obj)\n",
    "print len(V_subj.intersection(V_obj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. $S$ & $O$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vsubj2i = {v:i for i,v in enumerate(list(V_subj))}\n",
    "vobj2i = {v:i for i,v in enumerate(list(V_obj))}\n",
    "subj2i = {subj:i for i,subj in enumerate(list(W_subj))}\n",
    "obj2i = {obj:i for i,obj in enumerate(list(W_obj))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754 3319 232 394\n"
     ]
    }
   ],
   "source": [
    "print len(vsubj2i), len(vobj2i), len(subj2i), len(obj2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus_mat(triples, v2i, w2i, mode):\n",
    "    \n",
    "    corpus_mat = np.zeros((len(v2i),len(w2i)))\n",
    "    for triple in triples:\n",
    "        if triple[1].endswith(mode) and triple[0] in norms_set:\n",
    "            corpus_mat[v2i[triple[2]]][w2i[triple[0]]] += 1\n",
    "    \n",
    "    return corpus_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 789 ms, sys: 11.7 ms, total: 800 ms\n",
      "Wall time: 798 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "S = get_corpus_mat(dep_triples, vsubj2i, subj2i, 'subj')\n",
    "O = get_corpus_mat(dep_triples, vobj2i, obj2i, 'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3754, 232) (3319, 394)\n"
     ]
    }
   ],
   "source": [
    "print S.shape, O.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. $S'$ & $O'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = {df.ix[i]['Feature'] for i in range(df.shape[0])}\n",
    "f2i = {f:i for i,f in enumerate(features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_norm2feature_dict(df, w_set):\n",
    "    \n",
    "    norm2feature = defaultdict(int)\n",
    "    for i in xrange(df.shape[0]):\n",
    "        norm = norm_normalize(df.ix[i]['Concept'])\n",
    "        if norm in w_set:\n",
    "            prop = df.ix[i]['Feature']\n",
    "            norm2feature[(norm,prop)] = df.ix[i]['Prod_Freq'] # production frequency.\n",
    "    \n",
    "    return norm2feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accordion\n",
      "a_musical_instrument\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print df.ix[0]['Concept']\n",
    "print df.ix[0]['Feature']\n",
    "print df.ix[0]['Prod_Freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.64 s, sys: 78.5 ms, total: 5.72 s\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subjft_dict = make_norm2feature_dict(df, W_subj)\n",
    "objft_dict = make_norm2feature_dict(df, W_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjft_dict[('airplane','is_fast')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used_for_transportation 10\n",
      "is_fast 11\n",
      "used_for_travel 7\n",
      "has_a_propeller 5\n",
      "has_wings 20\n",
      "beh_-_flies 25\n",
      "is_large 8\n",
      "requires_pilots 11\n",
      "has_engines 5\n",
      "used_for_passengers 15\n",
      "found_in_airports 8\n",
      "made_of_metal 8\n",
      "inbeh_-_crashes 7\n"
     ]
    }
   ],
   "source": [
    "for prop in features:\n",
    "    count = subjft_dict[('airplane',prop)]\n",
    "    if count!=0: print prop, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_norm_mat(wft_dict, w2i):\n",
    "    \n",
    "    norm_mat = np.zeros((len(w2i),len(f2i)))\n",
    "    for w in w2i.iterkeys():\n",
    "        for prop in f2i.iterkeys():\n",
    "            norm_mat[w2i[w]][f2i[prop]] = wft_dict[(w,prop)]\n",
    "    \n",
    "    return norm_mat / 30 # cf. McRae\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 42.4 ms, total: 1.47 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "S_prime = make_norm_mat(subjft_dict, subj2i)\n",
    "O_prime = make_norm_mat(objft_dict, obj2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 2526) (394, 2526)\n"
     ]
    }
   ],
   "source": [
    "print S_prime.shape, O_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.366666666667\n"
     ]
    }
   ],
   "source": [
    "print S_prime[subj2i['airplane']][f2i['is_fast']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Obtain Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. $p(subj/obj\\mid v)$ & $p(prop\\mid subj/obj)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def div(x,y): return x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_subj_given_v(w, v):\n",
    "    return div(S[vsubj2i[v]][subj2i[w]], S[vsubj2i[v]].sum())\n",
    "def p_obj_given_v(w, v):\n",
    "    return div(O[vobj2i[v]][obj2i[w]], O[vobj2i[v]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166666666667\n"
     ]
    }
   ],
   "source": [
    "print p_obj_given_v('crocodile', 'feed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_prop_given_subj(prop, w, binary=1):\n",
    "    if binary:\n",
    "        return 1 if S_prime[subj2i[w]][f2i[prop]]!=0 else 0\n",
    "    return S_prime[subj2i[w]][f2i[prop]]\n",
    "def p_prop_given_obj(prop, w, binary=1):\n",
    "    if binary:\n",
    "        return 1 if O_prime[obj2i[w]][f2i[prop]]!=0 else 0\n",
    "    return O_prime[obj2i[w]][f2i[prop]]\n",
    "\n",
    "# Comments: Binary seems to make more sense -- even if only 1 person out of 30 says \n",
    "#     a crocodile is an animal, then it should be the case that 'crocodile is an animal'\n",
    "#     rather than 'crocodile has 20% chance to be an animal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print p_prop_given_obj('an_animal','crocodile')\n",
    "print p_prop_given_obj('an_animal','crocodile', binary=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. $p_{subj/obj}(prop\\mid v) \\propto \\sum_{subj\\in v_{subj/obj}}p(prop\\mid subj/obj)p(subj/obj\\mid v)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_subj_prop_given_v(prop, v, binary=1, cohort=subj2i.keys()):\n",
    "    return sum(p_prop_given_subj(prop,w,binary)*p_subj_given_v(w,v) for w in cohort)\n",
    "def p_obj_prop_given_v(prop, v, binary=1, cohort=obj2i.keys()):\n",
    "    return sum(p_prop_given_obj(prop,w,binary)*p_obj_given_v(w,v) for w in cohort)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "0.341772151899\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print p_obj_prop_given_v('an_animal','feed') # 'feed' is very specific to animals.\n",
    "print p_obj_prop_given_v('an_animal','like') # 'like' has a more varied object base.\n",
    "print p_obj_prop_given_v('an_animal','rise') # 'rise' cannot possibly take an animal for object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Infer Properties of \"New Words\" $w\\in norms$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get V:[n1...nn] dict, i.e. for paradigmatic cohort\n",
    "def get_arg_list(triples, argtype): # argtype = {subj, obj}\n",
    "    \n",
    "    arg_list = defaultdict(list)\n",
    "    for triple in triples:\n",
    "        if triple[1].endswith(argtype) and triple[0] in norms_set:\n",
    "            arg_list[triple[2]].append(triple[0])\n",
    "    \n",
    "    return arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 756 ms, sys: 14.5 ms, total: 771 ms\n",
      "Wall time: 769 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subj2args, obj2args = get_arg_list(dep_triples, 'subj'), get_arg_list(dep_triples, 'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'pig', u'corn', u'horse', u'rice', u'crocodile', u'cat']\n"
     ]
    }
   ],
   "source": [
    "print obj2args['feed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_subj_properties(w, v, topk=5):\n",
    "    \n",
    "    cohort = subj2args[v]\n",
    "    props = [p_subj_prop_given_v(prop,v,cohort) for prop in feature_list]\n",
    "    topk_props_idx = np.argsort(props)[::-1][:topk]\n",
    "    \n",
    "    for i,idx in enumerate(topk_props_idx):\n",
    "        print \"%dth Property: %s (prop=%.6f%%)\" % (i+1,feature_list[idx],prop[idx])\n",
    "\n",
    "def infer_obj_properties(w, v, topk=5):\n",
    "    \n",
    "    cohort = obj2args[v]\n",
    "    props = [p_obj_prop_given_v(prop,v,cohort) for prop in feature_list]\n",
    "    topk_props_idx = np.argsort(props)[::-1][:topk]\n",
    "    \n",
    "    for i,idx in enumerate(topk_props_idx):\n",
    "        print \"%dth Property: %s (prop=%.6f%%)\" % (i+1,feature_list[idx],props[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Property: has_4_legs (prop=0.666667%)\n",
      "2th Property: has_a_tail (prop=0.666667%)\n",
      "3th Property: an_animal (prop=0.666667%)\n",
      "4th Property: is_edible (prop=0.500000%)\n",
      "5th Property: has_legs (prop=0.500000%)\n"
     ]
    }
   ],
   "source": [
    "infer_obj_properties('crocodile','feed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Property: has_pages (prop=0.833333%)\n",
      "2th Property: has_words_in_it (prop=0.833333%)\n",
      "3th Property: has_authors (prop=0.833333%)\n",
      "4th Property: used_for_learning (prop=0.833333%)\n",
      "5th Property: has_a_hard_cover (prop=0.833333%)\n"
     ]
    }
   ],
   "source": [
    "infer_obj_properties('book','read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Leave-One-Out Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.G. 'alligator' (Single Exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observed: 'a guy is feeding an alligator.'\n",
    "# pred/arg: 'feed', 'alligator' as object.\n",
    "\n",
    "# Config: SPECIAL BLOCK ACTIVATED TEMPORARILY TO LEAVE 'ALLIGATOR' OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cohort(triples, v, argtype): # argtype = {subj, obj}\n",
    "    \n",
    "    args = []\n",
    "    for triple in triples:\n",
    "        if triple[1].endswith(argtype) \\\n",
    "            and triple[2]==v \\\n",
    "            and triple[0] in norms_set:\n",
    "            args.append(triple[0])\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_unknown_subj_properties(v, cohort, topk=5):\n",
    "\n",
    "    props = [p_subj_prop_given_v(prop,v,cohort) for prop in feature_list]\n",
    "    topk_props_idx = np.argsort(props)[::-1][:topk]\n",
    "    \n",
    "    for i,idx in enumerate(topk_props_idx):\n",
    "        print \"%dth Property: %s (prop=%.6f%%)\" % (i+1,feature_list[idx],prop[idx])\n",
    "\n",
    "def infer_unknown_obj_properties(v, cohort, topk=5):\n",
    "\n",
    "    props = [p_obj_prop_given_v(prop,v,cohort) for prop in feature_list]\n",
    "    topk_props_idx = np.argsort(props)[::-1][:topk]\n",
    "    \n",
    "    for i,idx in enumerate(topk_props_idx):\n",
    "        print \"%dth Property: %s (prop=%.6f%%)\" % (i+1,feature_list[idx],props[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'pig', u'corn', u'horse', u'rice', u'crocodile', u'cat']\n"
     ]
    }
   ],
   "source": [
    "feed_obj_cohort = get_cohort(dep_triples, 'feed', 'obj')\n",
    "print feed_obj_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Property: has_4_legs (prop=0.666667%)\n",
      "2th Property: has_a_tail (prop=0.666667%)\n",
      "3th Property: an_animal (prop=0.666667%)\n",
      "4th Property: is_edible (prop=0.500000%)\n",
      "5th Property: has_legs (prop=0.500000%)\n"
     ]
    }
   ],
   "source": [
    "infer_unknown_obj_properties('feed', feed_obj_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observed: 'John says he likes alligators.'\n",
    "# pred/arg: 'like', 'alligator' as object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'football', u'bag', u'pyramid', u'dove', u'dove', u'bomb', u'bull', u'balloon', u'strawberry', u'pear', u'pear', u'orange', u'stone', u'airplane', u'dog', u'knife', u'box', u'banner', u'bag', u'curtain', u'cat', u'horse', u'rabbit', u'elephant', u'spade', u'sheep', u'whip', u'drum', u'bear', u'toad', u'church', u'radio', u'cat', u'dandelion', u'horse', u'chicken', u'knife', u'cat', u'book', u'cat', u'cellar', u'ball', u'card', u'book', u'deer', u'spade', u'dolphin', u'cat', u'balloon', u'prune', u'belt', u'cap', u'stone', u'ball', u'cigar', u'fawn', u'cat', u'dog', u'sheep', u'marble', u'ring', u'gun', u'rooster', u'stone', u'cat', u'sheep', u'radio', u'toilet', u'mirror', u'banner', u'scarf', u'balloon', u'rope', u'candle', u'car', u'mole', u'calf', u'bat', u'balloon']\n"
     ]
    }
   ],
   "source": [
    "like_obj_cohort = get_cohort(dep_triples, 'like', 'obj')\n",
    "print like_obj_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Property: an_animal (prop=0.341772%)\n",
      "2th Property: has_4_legs (prop=0.253165%)\n",
      "3th Property: a_mammal (prop=0.240506%)\n",
      "4th Property: has_legs (prop=0.240506%)\n",
      "5th Property: beh_-_eats (prop=0.215190%)\n"
     ]
    }
   ],
   "source": [
    "infer_unknown_obj_properties('like', like_obj_cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Bayesian Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.G. 'alligator' (Multiple Exposure: Bayesian Update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a. *On our last evening, the boatman **killed** an **alligator** as it **crawled** past our camp-fire to go **hunting** in the reeds beyond.*\n",
    "* b. *He falls on the floor, belly up, wiggling happily, hands sticking out from the shoulders at a crazy **alligator** angle.*\n",
    "* c. *A study done by Edwin Colbert and his colleagues showed that a tiny 50 gramme (1.76 oz) alligator heated up 1C every minute and a half from the Sun, while a large **alligator** some 260 times bigger **took** seven and a half minutes.*\n",
    "* d. *The throne was occupied by a pipe-smoking **alligator**.*\n",
    "* e. *It was my idea of what an a**lligator** might **find** appealing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Three Levels of Informativeness (can be generalized to all kinds of dependencies, now restricted to core argument structure): \n",
    "    * i) Informative: Subj/Obj (wrt. pred) gives specific information.\n",
    "    * ii) Uninformative: Generally applicable information.\n",
    "    * iii) Noninformative: Not a core argument.\n",
    "* For Our Example ...\n",
    "    * a. [informative]\n",
    "        * Obj of *kill*, must be animal.\n",
    "        * Subj of *crawl*, must be animal, have legs.\n",
    "        * Subj of *hunt*, must be animal (in addition, predator).\n",
    "    * b. [noninformative]\n",
    "    * c. [uninformative]\n",
    "        * Subj of *heat up*, could be any concrete/abstract entity.\n",
    "        * Subj of *take*, could be anything literally.\n",
    "    * d. [noninformative]\n",
    "    * c. [uninformative]\n",
    "        * Subj of *find*, could be anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
